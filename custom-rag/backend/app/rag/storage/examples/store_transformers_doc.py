#!/usr/bin/env python3
"""
Example script to store transformers.md document in the database

This script demonstrates:
1. Reading a markdown file from disk
2. Storing it using DocumentStore with auto-chunking and embedding
3. Displaying storage results and statistics
"""

import os
import sys
import dotenv

# Load environment variables and override POSTGRES_HOST for Docker
dotenv.load_dotenv(".env.dev")
os.environ["POSTGRES_HOST"] = "localhost"

# Add the backend directory to Python path so we can import from app
sys.path.append(os.path.join(os.path.dirname(__file__), "../../../../"))

from app.rag.storage.document_store import DocumentStore
from app.db.connection import DatabaseService


async def store_transformers_document():
    """Store the transformers.md document in the database"""
    print("ğŸ“„ STORING TRANSFORMERS DOCUMENT")
    print("=" * 60)

    # Path to transformers.md file in rag/documents (relative to this script)
    script_dir = os.path.dirname(__file__)
    transformers_file = os.path.join(script_dir, "../../documents/transformers.md")
    transformers_file = os.path.abspath(transformers_file)  # Convert to absolute path

    try:
        # Read the markdown file
        print(f"ğŸ“– Reading file: {transformers_file}")
        with open(transformers_file, "r", encoding="utf-8") as f:
            content = f.read()

        print(f"âœ… File loaded: {len(content)} characters")

        # Connect to database
        db_service = DatabaseService()
        await db_service.initialize()

        async with db_service.get_connection() as conn:
            print("âœ… Connected to database")

            # Create document store with LLM summarization
            store = DocumentStore(
                db_connection=conn,
                embedding_provider="openai",  # Use OpenAI embeddings
                max_chunk_tokens=512,  # Reasonable chunk size
                max_chunk_words=200,
                llm_model="gpt-4o-mini",  # OpenAI model for summary
                use_llm_summary=True,  # Enable LLM-based summary
            )

            print(
                "âœ… Initialized DocumentStore with OpenAI embeddings and gpt-4o-mini summarization"
            )

            # Store the document
            print("\nğŸ“ Storing document...")
            result = await store.store_document(
                title="Attention Is All You Need",
                content=content,
                generate_summary=True,
            )

            print(f"ğŸ‰ Document stored successfully!")
            print(f"   ğŸ“„ Document ID: {result.document_id}")
            print(f"   ğŸ“ Title: {result.title}")
            print(f"   ğŸ“„ Summary: {result.summary[:150]}...")
            print(f"   ğŸ”¢ Total chunks: {result.total_chunks}")
            print(f"   ğŸ“Š Total tokens: {result.total_tokens}")
            print(f"   â±ï¸  Processing time: {result.processing_time:.3f}s")
            print(
                f"   ğŸ†” Chunk IDs: {result.chunk_ids[:5]}{'...' if len(result.chunk_ids) > 5 else ''}"
            )

            # Get storage stats
            print(f"\nğŸ“Š STORAGE STATISTICS")
            print("=" * 40)
            stats = await store.get_storage_stats()
            print(f"ğŸ“„ Total documents: {stats['total_documents']}")
            print(f"ğŸ“š Total chunks: {stats['total_chunks']}")
            print(f"ğŸ“ˆ Avg chunks per document: {stats['avg_chunks_per_document']:.1f}")
            print(f"ğŸ¤– Embedding provider: {stats['embedding_provider']}")

            return result.document_id

        await db_service.close()

    except FileNotFoundError:
        print(f"âŒ File not found: {transformers_file}")
        return None
    except Exception as e:
        print(f"âŒ Storage failed: {e}")
        import traceback

        traceback.print_exc()
        return None


async def main():
    """Main function to store transformers document"""
    print("ğŸš€ TRANSFORMERS DOCUMENT STORAGE")
    print("=" * 80)

    # Check environment
    if not os.getenv("POSTGRES_HOST"):
        print("âš ï¸  No database configuration found in .env.dev")
        print(
            "ğŸ’¡ Make sure POSTGRES_HOST, POSTGRES_DATABASE, POSTGRES_USER, POSTGRES_PASSWORD are set"
        )
        return

    if not os.getenv("OPENAI_API_KEY"):
        print("âš ï¸  No OPENAI_API_KEY found in .env.dev")
        print("ğŸ’¡ Make sure OPENAI_API_KEY is set for embeddings")
        return

    # Store the document
    document_id = await store_transformers_document()

    print(f"\n\nâœ¨ Transformers document storage completed! Document ID: {document_id}")


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
